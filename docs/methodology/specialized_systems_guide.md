



# Дополнение к универсальному шаблону: Проектирование специализированных ИИ-систем

Это дополнение расширяет универсальный шаблон, предоставляя конкретные архитектурные паттерны, структуру проектов и промпты для 5 распространённых типов ИИ-систем. Оно предполагает, что вы уже настроили базовый проект согласно универсальному шаблону (PCAM, GRACE, FLEX).

---

## Раздел 1: Платформы для Reinforcement Learning from Human Feedback (RLHF)

RLHF-платформа — это не просто модель, а полноценное веб-приложение для сбора человеческих предпочтений и дообучения языковых моделей. В контексте Django, это система, где аннотаторы ранжируют ответы ИИ, а их фидбек используется для тренировки "модели вознаграждения" (Reward Model).

### 1.1. Архитектура RLHF-платформы

Архитектура состоит из трёх ключевых компонентов: фронтенд для аннотаций, бэкенд для управления данными и асинхронный воркер для обучения. Эта система позволяет итеративно улучшать языковую модель на основе реальных человеческих предпочтений, что является ключевым для создания безопасных и полезных ИИ-ассистентов.

| Компонент | Технология | Назначение |
|---|---|---|
| **Интерфейс аннотаций** | Django Templates / React | Предоставление пар ответов (A/B) для сравнения и выбора лучшего. Интерфейс должен быть максимально простым и интуитивно понятным, чтобы минимизировать когнитивную нагрузку на аннотатора. |
| **Бэкенд (API)** | Django REST Framework | Приём и хранение промптов, ответов, и предпочтений пользователей. API должно быть надёжным и масштабируемым для обработки большого количества запросов. |
| **База данных** | PostgreSQL | Хранение структурированных данных: промпты, ответы, пользователи, их выборы. Использование реляционной базы данных позволяет легко связывать данные и делать сложные выборки. |
| **Очередь задач** | Celery + Redis/RabbitMQ | Асинхронное выполнение задач по дообучению Reward Model. Это позволяет не блокировать основной поток приложения и выполнять ресурсоёмкие операции в фоне. |
| **Тренировочный пайплайн** | HuggingFace TRL, PyTorch | Скрипты для SFT (Supervised Fine-Tuning), тренировки Reward Model и PPO-оптимизации. Это ядро RLHF-процесса. |

### 1.2. Структура Django-проекта

К базовой структуре проекта добавляется приложение `rlhf_platform`.

```
my_project/
├── .cursor/
│   ├── rules-architect.md
│   └── ...
├── .rules/
│   ├── grace.md
│   └── flex.xml
├── my_project/
│   └── ...
├── rlhf_platform/  <-- Новое приложение
│   ├── __init__.py
│   ├── admin.py
│   ├── apps.py
│   ├── models.py      # Модели Prompt, Response, Preference
│   ├── serializers.py # Сериализаторы для API
│   ├── views.py       # API-эндпоинты и страницы для аннотаций
│   ├── urls.py
│   └── tasks.py       # Celery-задачи для обучения
├── static/
├── templates/
├── DEVELOPMENT_PLAN.md
├── manage.py
└── USER_PROFILE.xml
```

### 1.3. Микрошаги по реализации

1.  **Настройка проекта:** Следуйте универсальному шаблону для создания базового Django-проекта.
2.  **Создание приложения:** `python manage.py startapp rlhf_platform`
3.  **Определение моделей (`models.py`):**

    ```python
    # rlhf_platform/models.py
    from django.db import models
    from django.contrib.auth.models import User

    class Prompt(models.Model):
        """Исходный промпт, который инициирует генерацию ответов."""
        text = models.TextField(unique=True)
        created_at = models.DateTimeField(auto_now_add=True)

        def __str__(self):
            return self.text[:80]

    class ResponsePair(models.Model):
        """Пара сгенерированных ответов (A и B) для одного промпта."""
        prompt = models.ForeignKey(Prompt, on_delete=models.CASCADE, related_name='response_pairs')
        response_a = models.TextField()
        response_b = models.TextField()
        created_at = models.DateTimeField(auto_now_add=True)

    class Preference(models.Model):
        """Предпочтение, отданное аннотатором одному из ответов."""
        CHOSEN_CHOICES = (
            ('A', 'Response A'),
            ('B', 'Response B'),
            ('E', 'Equally good/bad'),
        )
        response_pair = models.ForeignKey(ResponsePair, on_delete=models.CASCADE, related_name='preferences')
        annotator = models.ForeignKey(User, on_delete=models.CASCADE)
        chosen = models.CharField(max_length=1, choices=CHOSEN_CHOICES)
        created_at = models.DateTimeField(auto_now_add=True)
    ```

4.  **Разработка API (`views.py`, `serializers.py`):**
    *   Эндпоинт для получения следующей пары ответов для аннотации.
    *   Эндпоинт для сохранения выбора пользователя.

5.  **Создание Celery-задачи (`tasks.py`):**

    ```python
    # rlhf_platform/tasks.py
    from celery import shared_task
    from .models import Preference
    from huggingface_hub import HfApi
    import pandas as pd
    import os

    @shared_task
    def export_preferences_to_hf_dataset():
        """Собирает все предпочтения и выгружает их в датасет на Hugging Face."""
        preferences = Preference.objects.all().values(
            'response_pair__prompt__text',
            'response_pair__response_a', 
            'response_pair__response_b', 
            'chosen'
        )
        df = pd.DataFrame(list(preferences))
        df.rename(columns={
            'response_pair__prompt__text': 'prompt',
            'response_pair__response_a': 'chosen_response' if 'A' else 'rejected_response',
            'response_pair__response_b': 'rejected_response' if 'A' else 'chosen_response',
        }, inplace=True) # Упрощенная логика, требует доработки

        dataset_path = 'rlhf_preferences.csv'
        df.to_csv(dataset_path, index=False)

        api = HfApi()
        api.upload_file(
            path_or_fileobj=dataset_path,
            path_in_repo="data/rlhf_preferences.csv",
            repo_id=os.environ.get("HF_REPO_ID"),
            repo_type="dataset",
        )
        os.remove(dataset_path)
        return f"Successfully uploaded {len(df)} preferences."
    ```

### 1.4. Тестирование и валидация

Тестирование RLHF-системы включает в себя как стандартные тесты для Django-приложения, так и специфические для ML.

*   **Unit-тесты:** Проверьте API-эндпоинты, корректность сохранения моделей в базу данных.
*   **Интеграционные тесты:** Убедитесь, что Celery-задача корректно запускается и обрабатывает данные.
*   **Валидация данных:** Напишите скрипты для проверки консистентности собранных данных перед обучением (например, отсутствие дубликатов, корректные форматы).
*   **Оценка модели вознаграждения:** После обучения Reward Model, оцените её точность на отложенной выборке. Точность должна быть значительно выше 50%.

### 1.5. Шаблон файла `rules-architect.md` для RLHF

```markdown
@USER_PROFILE.xml
@rules/grace.md
@rules/flex.xml

**Контекст:** Мы создаём RLHF-платформу. Уже есть приложение `rlhf_platform` с моделями `Prompt`, `ResponsePair`, `Preference`.

**Задача:** Спроектируй API-view `get_next_pair_for_annotation` в `rlhf_platform/views.py`. Этот view должен возвращать следующую пару ответов, которую текущий пользователь ещё не аннотировал.

**План (PCAM):**
- **Purpose:** Создать эндпоинт для выдачи данных аннотаторам.
- **Context:** Django REST Framework, существующие модели, аутентифицированный пользователь.
- **Audience:** Я, разработчик.
- **Medium:** Код в `rlhf_platform/views.py`.

**THINKING_TOKENS:**
- Сначала нужно получить текущего пользователя (`request.user`).
- Затем нужно найти все `ResponsePair`, которые он уже аннотировал. Это можно сделать через обратную связь от `Preference` к `ResponsePair`.
- После этого нужно выбрать один `ResponsePair`, который ещё не был аннотирован этим пользователем. `exclude()` в Django ORM здесь идеально подойдёт.
- Если таких пар нет, нужно вернуть соответствующий статус (например, 204 No Content).
- Не забыть про сериализацию данных перед отправкой.
```


---

## Раздел 2: Системы поддержки принятия решений (СППР) на базе ИИ

СППР (Decision Support System, DSS) — это система, которая помогает пользователям принимать решения, анализируя большие объёмы данных и предоставляя рекомендации. В отличие от полностью автономных систем, СППР оставляет финальное решение за человеком, выступая в роли интеллектуального советника.

### 2.1. Архитектура СППР

Архитектура СППР строится вокруг цикла "Данные → Анализ → Рекомендация → Действие". Центральным элементом является база знаний, которая позволяет системе делать выводы на основе релевантной информации.

| Компонент | Технология | Назначение |
|---|---|---|
| **Слой данных** | PostgreSQL, Data Warehouse | Сбор и хранение сырых данных из различных источников (базы данных, логи, CRM). |
| **Слой обработки (ETL)** | Django Commands, N8n | Извлечение, трансформация и загрузка данных в витрины данных. На этом этапе данные очищаются и структурируются. |
| **База знаний (Knowledge Base)** | RAG (Retrieval-Augmented Generation) с `pgvector` | Индексация документов, инструкций и исторических данных для поиска релевантной информации. RAG позволяет LLM использовать актуальные данные, которые не были частью её первоначального обучения. |
| **Движок вывода (Inference Engine)** | LLM (GPT, Claude, Llama) | Анализ текущей ситуации, поиск по базе знаний и генерация рекомендаций с объяснениями. |
| **Слой представления** | Django Templates / React | Визуализация данных и сгенерированных рекомендаций в удобном для пользователя виде (дашборды, графики, текстовые саммари). |

### 2.2. Структура Django-проекта

К базовому проекту добавляется приложение `dss`.

```
my_project/
├── ...
├── dss/  <-- Новое приложение
│   ├── __init__.py
│   ├── models.py      # Модели для хранения данных, решений и логов
│   ├── services.py    # Бизнес-логика, интеграция с LLM и RAG
│   ├── management/
│   │   └── commands/  # ETL-скрипты
│   │       └── process_data.py
│   └── views.py       # API для фронтенда
├── ...
```

### 2.3. Микрошаги по реализации

1.  **Настройка ETL:** Создайте Django-команду для регулярного сбора и обработки данных. Используйте `pandas` для удобной манипуляции данными.
2.  **Создание Базы Знаний:** Используйте `pgvector` в PostgreSQL для хранения векторных представлений документов. Напишите сервис для RAG-поиска, который по текстовому запросу находит наиболее релевантные чанки текста.
3.  **Разработка Движка Вывода (`services.py`):**

    ```python
    # dss/services.py
    import openai
    from .rag import find_relevant_documents

    class DecisionEngine:
        def get_recommendation(self, current_data: dict) -> dict:
            """Генерирует рекомендацию на основе текущих данных и базы знаний."""
            relevant_docs = find_relevant_documents(str(current_data))
            
            prompt = f"""Контекст: {relevant_docs}

Данные: {current_data}

Проанализируй данные и контекст, и дай свою рекомендацию. Оцени свою уверенность по шкале от 0 до 1."""

            response = openai.ChatCompletion.create(
                model="gpt-4.1-mini",
                messages=[{"role": "user", "content": prompt}]
            )
            
            # Здесь нужен парсинг ответа, чтобы извлечь текст и оценку уверенности
            # Для надежности лучше использовать Function Calling или JSON mode
            content = response.choices[0].message.content
            return {"recommendation": content, "confidence_score": 0.85} # Заглушка
    ```

4.  **Создание промпта для Cursor (режим Кодирования):**

    ```markdown
    @USER_PROFILE.xml
    @rules/grace.md
    @dss/services.py

    **Контекст:** Мы создаём сервис для генерации рекомендаций в СППР. Нужно реализовать функцию `get_recommendation` в `dss/services.py`.

    **Задача:** Напиши код для функции `get_recommendation(current_data)`. Она должна:
    1. Найти релевантные документы из Базы Знаний (RAG) с помощью функции `find_relevant_documents`.
    2. Сформировать промпт для LLM, включающий `current_data` и найденные документы.
    3. Вызвать LLM и вернуть его ответ вместе с `Confidence Score`.

    **THINKING_TOKENS:**
    - Сначала нужно будет импортировать сервис для RAG-поиска.
    - Затем — клиент для LLM.
    - Промпт должен быть структурированным, чтобы LLM вернул и текст, и оценку уверенности. Лучше всего использовать JSON mode, если модель его поддерживает.
    ```

### 2.4. Тестирование и валидация

*   **Тестирование ETL:** Убедитесь, что данные извлекаются и трансформируются корректно. Напишите тесты, которые проверяют схему и качество данных после обработки.
*   **Тестирование RAG:** Проверьте, что для типовых запросов RAG-система возвращает действительно релевантные документы.
*   **Оценка качества рекомендаций:** Создайте "золотой датасет" с примерами входных данных и эталонными рекомендациями, составленными экспертом. Сравните рекомендации вашей системы с эталонными, используя метрики, такие как BLEU или ROUGE, или просто экспертную оценку.


---

## Раздел 3: ИИ-агенты

ИИ-агент — это автономная сущность, которая может воспринимать окружение, принимать решения и выполнять действия для достижения цели. В отличие от СППР, агент может действовать без прямого одобрения человека, что открывает возможности для полной автоматизации сложных задач.

### 3.1. Архитектура ИИ-агента (Паттерн ReAct)

ReAct (Reason + Act) — один из самых популярных и эффективных паттернов для создания агентов. Цикл работы агента состоит из размышления (Reason) и действия (Act).

| Компонент | Технология | Назначение |
|---|---|---|
| **Мозг (Brain)** | LLM (GPT-4, Claude 3) | Центральный компонент, который анализирует цель, историю, и доступные инструменты, а затем решает, что делать дальше. |
| **Инструменты (Tools)** | Python-функции с docstrings | Набор доступных агенту действий (например: `поиск_в_интернете`, `создать_файл`, `выполнить_shell_команду`). LLM использует docstrings для понимания, какой инструмент для чего нужен. |
| **Память (Memory)** | База данных / Файлы | Хранение истории действий, результатов и извлечённых знаний. Память может быть краткосрочной (история текущей сессии) и долгосрочной (векторная база знаний). |
| **Цикл (Loop)** | While-цикл / Celery | Оркестрация цикла "Reason → Act → Observe". Цикл продолжается, пока не будет достигнута конечная цель. |

### 3.2. Структура Django-проекта

```
my_project/
├── ...
├── agents/  <-- Новое приложение
│   ├── __init__.py
│   ├── models.py      # Модель Agent для хранения конфигурации и истории
│   ├── tools/         # Директория для инструментов
│   │   ├── __init__.py
│   │   └── web_search.py
│   ├── memory.py      # Классы для управления памятью
│   └── agent_loop.py  # Основной цикл работы агента
├── ...
```

### 3.3. Микрошаги по реализации

1.  **Определение инструментов:** Создайте Python-функции, которые агент сможет вызывать. Каждая функция должна иметь чёткое описание (docstring) — оно будет использоваться LLM для выбора инструмента. Используйте `pydantic` для строгой типизации аргументов.

    ```python
    # agents/tools/web_search.py
    from pydantic import BaseModel, Field

    class WebSearchInput(BaseModel):
        query: str = Field(description="Поисковый запрос для поиска в интернете")

    def web_search(args: WebSearchInput) -> str:
        """Ищет информацию в интернете по заданному запросу."""
        # ... реализация поиска ...
        return "Результаты поиска..."
    ```

2.  **Реализация памяти:** Создайте класс для управления памятью, который может сохранять и извлекать историю диалога и действий.
3.  **Создание цикла агента:** Напишите основной цикл, который на каждой итерации:
    *   Формирует промпт с текущей целью, историей и доступными инструментами.
    *   Вызывает LLM (желательно с поддержкой Function Calling).
    *   Парсит ответ LLM, чтобы определить, какой инструмент вызвать и с какими аргументами.
    *   Вызывает инструмент и получает результат (Observation).
    *   Сохраняет результат в память и переходит к следующей итерации.
4.  **Создание промпта для Cursor (режим Отладки):**

    ```markdown
    @USER_PROFILE.xml
    @rules/grace.md
    @agents/agent_loop.py

    **Контекст:** Агент неправильно выбирает инструмент. Вместо `web_search` он пытается вызвать несуществующий `google_search`.

    **Задача:** Проанализируй `agent_loop.py` и лог вызовов LLM. Найди причину ошибки и предложи исправление.

    **THINKING_TOKENS:**
    - Гипотеза 1: Ошибка в промпте, который мы отправляем LLM. Возможно, описания инструментов (docstrings) недостаточно ясные или формат представления инструментов не соответствует ожиданиям модели.
    - Гипотеза 2: Ошибка в парсинге ответа LLM. Возможно, я неправильно извлекаю имя инструмента или его аргументы.
    - План: Сначала проверю, как формируется список инструментов в промпте. Затем проверю код парсинга. Возможно, стоит добавить логирование полного промпта и ответа от LLM.
    ```

### 3.4. Тестирование и валидация

*   **Тестирование инструментов:** Каждый инструмент должен быть покрыт unit-тестами, чтобы гарантировать его корректную и предсказуемую работу.
*   **Тестирование цикла агента:** Напишите интеграционные тесты, которые проверяют, что агент может выполнить простую задачу из нескольких шагов (например, "найди информацию о X и сохрани её в файл Y").
*   **Оценка производительности:** Используйте фреймворки для оценки агентов, такие как `agenteval` или `tool-eval`, чтобы измерить, насколько успешно агент справляется с набором тестовых задач. Это поможет отслеживать прогресс при улучшении промптов или добавлении новых инструментов.


---

## Раздел 4: Мультиагентные системы

Мультиагентная система — это система, в которой несколько ИИ-агентов взаимодействуют друг с другом для решения сложной задачи, недоступной одному агенту. Это похоже на команду специалистов, где каждый имеет свою роль (например, Исследователь, Программист, Тестировщик), и они работают вместе под руководством менеджера (Оркестратора).

### 4.1. Архитектура мультиагентной системы

Ключевой компонент — **Оркестратор**, который управляет взаимодействием агентов. Популярные фреймворки, такие как CrewAI, LangChain и AutoGen, предоставляют готовые блоки для построения таких систем.

| Компонент | Технология | Назначение |
|---|---|---|
| **Оркестратор (Orchestrator)** | CrewAI / LangChain | Принимает общую задачу, декомпозирует её на подзадачи и распределяет их между агентами. Контролирует поток выполнения. |
| **Пул Агентов (Agent Pool)** | CrewAI / AutoGen | Набор специализированных агентов, каждый со своей ролью, набором инструментов и, возможно, собственной LLM. |
| **Общая Память (Shared Memory)** | PostgreSQL / Redis | Место, где агенты могут обмениваться информацией, артефактами и результатами своей работы. |
| **Шина Сообщений (Message Bus)** | RabbitMQ / WebSocket | Канал для асинхронного общения между агентами и оркестратором, особенно в распределённых системах. |

### 4.2. Структура Django-проекта с CrewAI

```
my_project/
├── ...
├── multi_agent/
│   ├── __init__.py
│   ├── models.py        # Модели Task, SubTask, Agent
│   ├── agents/          # Конфигурации и промпты для каждого агента
│   │   ├── researcher.py
│   │   └── coder.py
│   ├── tasks.py         # Celery-задача для запуска Crew
│   ├── crews.py         # Определение "команд" (Crews) из агентов
│   └── services.py      # Основной сервис для запуска системы
├── ...
```

### 4.3. Микрошаги по реализации с CrewAI

1.  **Определение ролей (Агентов):** В `agents/` определите каждого агента, его роль (`role`), цель (`goal`) и предысторию (`backstory`).

    ```python
    # multi_agent/agents/researcher.py
    from crewai import Agent

    researcher = Agent(
        role='Senior Research Analyst',
        goal='Uncover cutting-edge developments in AI and data science',
        backstory='You work at a leading tech think tank...',
        verbose=True,
        allow_delegation=False
    )
    ```

2.  **Определение Задач:** Опишите задачи, которые будут выполнять агенты. Каждая задача привязывается к конкретному агенту.
3.  **Сборка Команды (Crew):** В `crews.py` объедините агентов и задачи в единую команду (`Crew`).

    ```python
    # multi_agent/crews.py
    from crewai import Crew, Process
    from .agents import researcher, coder
    from .tasks import research_task, code_task

    tech_crew = Crew(
        agents=[researcher, coder],
        tasks=[research_task, code_task],
        process=Process.sequential
    )
    ```

4.  **Запуск в Celery:** Оберните запуск команды в Celery-задачу, чтобы избежать блокировки основного потока.

    ```python
    # multi_agent/tasks.py
    from celery import shared_task
    from .crews import tech_crew

    @shared_task
    def run_tech_crew(topic):
        return tech_crew.kickoff(inputs={\'topic\': topic})
    ```

5.  **Создание промпта для Cursor (режим Архитектора):**

    ```markdown
    @USER_PROFILE.xml
    @rules/grace.md
    @multi_agent/crews.py

    **Контекст:** Мы создаём мультиагентную систему для написания кода с помощью CrewAI. У нас есть `researcher_agent` и `coder_agent`.

    **Задача:** Спроектируй `Crew` в `multi_agent/crews.py`. Он должен последовательно выполнять две задачи: сначала исследование, потом кодирование. Результат первой задачи должен передаваться во вторую.

    **План (PCAM):**
    - **Purpose:** Создать команду агентов, которая автоматизирует процесс "исследуй и напиши код".
    - **Context:** CrewAI, Django, Celery.
    - **Audience:** Я, разработчик.
    - **Medium:** Код в `multi_agent/crews.py`.

    **THINKING_TOKENS:**
    - CrewAI автоматически передает контекст между последовательными задачами, так что мне не нужно беспокоиться о ручной передаче данных.
    - Важно правильно определить `tasks` в `Crew`. Порядок имеет значение при `Process.sequential`.
    - Нужно убедиться, что `research_task` и `code_task` корректно определены и импортированы.
    ```

### 4.4. Тестирование и валидация

*   **Тестирование агентов:** Изолированно тестируйте каждого агента, чтобы убедиться, что он может выполнять свою основную функцию.
*   **Тестирование команды:** Запускайте всю команду на небольших, контролируемых задачах и проверяйте, что итоговый результат соответствует ожиданиям.
*   **Логирование и отладка:** CrewAI имеет `verbose=True` режим, который очень полезен для отладки. Сохраняйте логи выполнения каждой команды, чтобы анализировать, где и почему произошли сбои или неоптимальные решения.


---

## Раздел 5: Простые ИИ-инструменты

Это категория небольших, узкоспециализированных утилит, которые решают одну конкретную задачу с помощью ИИ. Примеры — удаление фона с фотографии, транскрибация аудио, генерация субтитров. Ключевая идея — инкапсулировать одну сложную операцию в простой и надёжный API.

### 5.1. Архитектура простого ИИ-инструмента

Архитектура обычно представляет собой простой пайплайн, где задача выполняется асинхронно, чтобы не блокировать пользователя.

| Компонент | Технология | Назначение |
|---|---|---|
| **API-эндпоинт** | Django REST Framework | Принимает входные данные (например, файл), валидирует их и ставит задачу в очередь. |
| **Асинхронный воркер** | Celery | Выполняет ресурсоёмкую ИИ-обработку в фоне. Это критически важно для отзывчивости приложения. |
| **ИИ-модель** | Pre-trained Model (`rembg`, `whisper`) | Готовая модель, которая выполняет основную работу. Использование open-source моделей значительно ускоряет разработку. |
| **Хранилище** | Файловая система / S3 | Хранение исходных и обработанных файлов. S3-совместимые хранилища предпочтительнее для масштабируемости. |

### 5.2. Структура Django-проекта

```
my_project/
├── ...
├── ai_tools/
│   ├── __init__.py
│   ├── models.py    # Модель для хранения ссылок на файлы и статуса обработки
│   ├── tasks.py     # Celery-задача для обработки
│   └── views.py     # API для загрузки файла и получения результата
├── ...
```

### 5.3. Микрошаги по реализации

1.  **Выбор и тестирование модели:** Найдите готовую open-source модель для вашей задачи. Перед интеграцией протестируйте её в отдельном скрипте, чтобы понять её требования и производительность.
2.  **Создание API (`views.py`):** Разработайте эндпоинт, который принимает файл, сохраняет его и создаёт Celery-задачу для его обработки.

    ```python
    # ai_tools/views.py
    from rest_framework.views import APIView
    from rest_framework.response import Response
    from .models import ProcessingRequest
    from .tasks import process_image_background

    class BackgroundRemovalView(APIView):
        def post(self, request, format=None):
            file_obj = request.data["file"]
            # Сохраняем файл и создаем запись в БД
            processing_request = ProcessingRequest.objects.create(input_file=file_obj)
            # Запускаем асинхронную задачу
            process_image_background.delay(processing_request.id)
            return Response({"request_id": processing_request.id}, status=202)
    ```

3.  **Реализация задачи (`tasks.py`):** В Celery-задаче инкапсулируйте всю логику работы с моделью.

    ```python
    # ai_tools/tasks.py
    from celery import shared_task
    from .models import ProcessingRequest
    from rembg import remove
    from PIL import Image
    import io

    @shared_task
    def process_image_background(request_id):
        try:
            request = ProcessingRequest.objects.get(id=request_id)
            request.status = 'processing'
            request.save()

            input_image = Image.open(request.input_file)
            output_image_bytes = remove(input_image)
            
            # Сохраняем результат
            # ... (логика сохранения файла и обновления request.output_file)

            request.status = 'completed'
            request.save()
        except Exception as e:
            request.status = 'failed'
            request.error_message = str(e)
            request.save()
    ```

4.  **Создание промпта для Cursor (режим Кодирования):**

    ```markdown
    @USER_PROFILE.xml
    @rules/grace.md
    @ai_tools/tasks.py

    **Контекст:** Мы создаём инструмент для удаления фона с изображений с помощью библиотеки `rembg`.

    **Задача:** Напиши код для Celery-задачи `process_image_background(request_id)` в `ai_tools/tasks.py`. Задача должна получить `ProcessingRequest` по ID, обработать изображение из `input_file` с помощью `rembg.remove`, сохранить результат в `output_file` и обновить статус задачи.

    **THINKING_TOKENS:**
    - Нужно импортировать `rembg`, `Pillow` и модель `ProcessingRequest`.
    - Открыть изображение, применить `rembg.remove()`, сохранить результат в байтовый поток.
    - Django `FileField` требует объект `ContentFile` для сохранения из памяти.
    - Обязательно обернуть логику в `try...except` для обработки ошибок и обновления статуса на `failed`.
    ```

### 5.4. Тестирование и валидация

*   **Unit-тесты API:** Проверьте, что API-эндпоинт корректно принимает файлы, создаёт запись в БД и ставит задачу в очередь Celery.
*   **Тесты воркера:** Напишите тест, который вызывает Celery-задачу напрямую (`.delay().get()`) с тестовым изображением и проверяет, что статус задачи меняется на `completed` и выходной файл создаётся.
*   **Качественная оценка:** Для ИИ-инструментов важна не только работоспособность, но и качество результата. Подготовьте небольшой датасет с типичными и сложными случаями (например, изображения с волосами для `rembg`) и визуально оцените результат работы модели.
